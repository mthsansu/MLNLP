{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mthsansu/MLNLP/blob/main/Code/Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **In all your experiments you should compare the performance of your models with simpler models (baselines). Baseline models should correspond to the most simple model you can build to solve your task. It could be a rule-based system, or a simple machine learning / deep-learning based system**"
      ],
      "metadata": {
        "id": "EFGwfrD2lICt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import modules and frameworks\n",
        "#! pip install transformers\n",
        "#! pip install torchinfo"
      ],
      "metadata": {
        "id": "-Ube2C4hmf2N"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "from nltk.tokenize import TreebankWordTokenizer, TweetTokenizer\n",
        "import pandas as pd\n",
        "from termcolor import colored\n",
        "from collections import Counter\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "BU09xYDdmo5k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data\n",
        "git_url = \"https://raw.githubusercontent.com/mthsansu/MLNLP/main/Data/\"\n",
        "df = pd.read_csv(git_url + 'df_label_sentiment.csv')\n"
      ],
      "metadata": {
        "id": "PMyA_0eIdlbE"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df. rename(columns = {'test':'Label == sentiment'}, inplace = True)\n",
        "df = df[[\"text\", \"Label\"]]\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LbpwFvyAeC_e",
        "outputId": "fd060023-395f-4d55-f833-caf7c0242a31"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  Label\n",
              "0  Article de Var Matin, ce jour, sur la proposit...      0\n",
              "1  Je me réjouis de l’annonce du @gouvernementFR ...      1\n",
              "2  Une fois guéris, les enfants hospitalisés au @...      1\n",
              "3  « Progressivement nous devons avoir une foncti...      0\n",
              "4  Réaction commune, avec ma collègue députée Sab...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a927db2c-a81d-4807-8fd6-8e646a79ae97\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Article de Var Matin, ce jour, sur la proposit...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Je me réjouis de l’annonce du @gouvernementFR ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Une fois guéris, les enfants hospitalisés au @...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>« Progressivement nous devons avoir une foncti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Réaction commune, avec ma collègue députée Sab...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a927db2c-a81d-4807-8fd6-8e646a79ae97')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a927db2c-a81d-4807-8fd6-8e646a79ae97 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a927db2c-a81d-4807-8fd6-8e646a79ae97');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df, test_size=0.2)"
      ],
      "metadata": {
        "id": "E7SiTiEbxwCp"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.to_dict('records')\n",
        "test = test.to_dict('records')"
      ],
      "metadata": {
        "id": "QARuWG9My1nC"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwYJCPBkjBfI",
        "outputId": "b0b799b9-2b61-414d-964c-1c64b3d291a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'have', 'a', 'new', 'gpu', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Use TweetTokenizer\n",
        "tok = TweetTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define useful functions\n",
        "def tokenize_pad_numericalize(entry, vocab_stoi, max_length=20):\n",
        "  text = [ vocab_stoi[token] if token in vocab_stoi else vocab_stoi['<unk>'] for token in tok.tokenize(entry.lower())]\n",
        "  padded_text = None\n",
        "  if len(text) < max_length:   padded_text = text + [ vocab_stoi['<pad>'] for i in range(len(text), max_length) ] \n",
        "  elif len(text) > max_length: padded_text = text[:max_length]\n",
        "  else:                        padded_text = text\n",
        "  return padded_text\n",
        "\n",
        "def tokenize_all(entries, vocab_stoi):\n",
        "  res = {}\n",
        "  res['text'] = [tokenize_pad_numericalize(entry, vocab_stoi, max_length=200) for entry in entries['text']]\n",
        "  res['label'] = entries['label']\n",
        "  return res"
      ],
      "metadata": {
        "id": "OZ-fB9mwlHLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the model \n",
        "class MinimalExampleModel(torch.nn.Module):\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "        \"\"\"\n",
        "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
        "        member variables.\n",
        "        \"\"\"\n",
        "        super(MinimalExampleModel, self).__init__()\n",
        "        # define a first linear layer with an input dimension (D_in) and a Hidden dimension (H)\n",
        "        # linear layer documentation: https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear\n",
        "        self.linear1 = torch.nn.Linear(D_in, H, bias=True)\n",
        "        # define the final linear layer, often named classification layer as the output dimension (D_out) == the number of target classes\n",
        "        self.linear2 = torch.nn.Linear(H, D_out, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        In the forward function we accept a Tensor of input data and we must return\n",
        "        a Tensor of output data. We can use Modules defined in the constructor as\n",
        "        well as arbitrary operators on Tensors.\n",
        "        \"\"\"\n",
        "        # first apply the linear1 layer on the vector and encapsulate it with an activation function for non linearization. This creates a dense layer.\n",
        "        # relu documentation: https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU \n",
        "        h_relu = torch.relu(self.linear1(x))\n",
        "        y_pred = self.linear2(h_relu)\n",
        "        return y_pred"
      ],
      "metadata": {
        "id": "D5CdqPbDmVz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instanciating the model with\n",
        "# N:      batch size\n",
        "# D_in:   input dimension\n",
        "# H:      hidden dimension\n",
        "# D_out:  output dimension\n",
        "N, D_in, H, D_out = 2, 10, 10, 2\n",
        "\n",
        "# Construct our model by instantiating the class defined above \n",
        "# Note: all the parameters are initialized here \n",
        "model = MinimalExampleModel(D_in, H, D_out)\n",
        "# You can look up into the model \n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qick4JFhoiEZ",
        "outputId": "31004dc4-54a0-48bb-c786-8f7d29ea2942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinimalExampleModel(\n",
              "  (linear1): Linear(in_features=10, out_features=10, bias=True)\n",
              "  (linear2): Linear(in_features=10, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's use torchinfo to have a better insight of the model infos: https://github.com/TylerYep/torchinfo\n",
        "from torchinfo import summary\n",
        "dummy_input_size = (1, 10) # (batch_size, D_in)\n",
        "summary(model, (N, D_in))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngJoPXP5ovSB",
        "outputId": "b90e8f08-986e-4cc0-b521-6ca7b9f1da15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "MinimalExampleModel                      --                        --\n",
              "├─Linear: 1-1                            [2, 10]                   110\n",
              "├─Linear: 1-2                            [2, 2]                    22\n",
              "==========================================================================================\n",
              "Total params: 132\n",
              "Trainable params: 132\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create random Tensors to hold inputs and outputs\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)"
      ],
      "metadata": {
        "id": "vKSo83bdo0qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "  print('DEVICE = ', colored(torch.cuda.get_device_name(0), \"green\" ) )\n",
        "else:\n",
        "  device = 'cpu'\n",
        "  print('DEVICE = ', colored('CPU', \"blue\"))\n",
        "model = model.to(device)\n",
        "\n",
        "#model = MyModel(D_in, H, D_out)\n",
        "# forward pass / predict x \n",
        "y_pred = model(x.to(device)) # almost equivalent to model.forward(x)\n",
        "# y_pred\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzBRFA4ro5Ez",
        "outputId": "943b7e7c-c05a-4c91-a005-1c8eb4030e70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE =  \u001b[34mCPU\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4117, -0.1531],\n",
              "        [-0.2486, -0.3666]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model to classify tweets\n",
        "class TweetModel(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, pretrained_vectors=None):\n",
        "        \"\"\"\n",
        "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
        "        member variables.\n",
        "        \"\"\"\n",
        "        super(TweetModel, self).__init__()\n",
        "        # apply the pretrained embeddings to transform our token indices, into vectors\n",
        "        self.ebd = torch.nn.Embedding.from_pretrained(pretrained_vectors, freeze=True)\n",
        "        self.hidden_linear_layer = torch.nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
        "        self.classification_layer = torch.nn.Linear(hidden_dim, output_dim, bias=True)\n",
        "        # softmax layer to compute class probabilities\n",
        "        # https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html?highlight=softmax#torch.nn.Softmax\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "        # define the dropout strategy (here, 20% (0.2) of the vector is ignored to prevent overfitting)\n",
        "        # we don't use it here but it's a good thing to keep in mind\n",
        "        # self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        In the forward function we accept a Tensor of input data and we must return\n",
        "        a Tensor of output data. We can use Modules defined in the constructor as\n",
        "        well as arbitrary operators on Tensors.\n",
        "        \"\"\"\n",
        "        # apply the pretrained embeddings\n",
        "        x  = self.ebd(x)\n",
        "        x  = x.mean(1)\n",
        "        h  = torch.relu(self.hidden_linear_layer( x ))\n",
        "        # h  = self.dropout(h)\n",
        "        h  = self.classification_layer(h)\n",
        "        logits = self.softmax(h)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "YY77yL_eo81v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}