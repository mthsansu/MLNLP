{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO/rsp8ej3rlscgbOUnZR9z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "824404c329a24440aef6207074197f2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_887a138e59d04e3c9674dde064ac6278",
              "IPY_MODEL_5c7d3228a72a4209a355cae288b844ce",
              "IPY_MODEL_696a603a2eb442f895ec6a23ef921be3"
            ],
            "layout": "IPY_MODEL_589d834e1d744425b97c1355485425a5"
          }
        },
        "887a138e59d04e3c9674dde064ac6278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa1b12be5a654cad93a1e3acdb0cc381",
            "placeholder": "​",
            "style": "IPY_MODEL_0498f04b3d5b41a6ad2b453b5fe9ead5",
            "value": "100%"
          }
        },
        "5c7d3228a72a4209a355cae288b844ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21054baf6e9149bfb9858b70b8407320",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1906924a76a349aeba20575bf98fc6eb",
            "value": 1
          }
        },
        "696a603a2eb442f895ec6a23ef921be3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a138bbee84f43d099c179464dc528b2",
            "placeholder": "​",
            "style": "IPY_MODEL_a1046be67917422199101bb8393242ba",
            "value": " 1/1 [00:05&lt;00:00,  5.43s/ba]"
          }
        },
        "589d834e1d744425b97c1355485425a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa1b12be5a654cad93a1e3acdb0cc381": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0498f04b3d5b41a6ad2b453b5fe9ead5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21054baf6e9149bfb9858b70b8407320": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1906924a76a349aeba20575bf98fc6eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a138bbee84f43d099c179464dc528b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1046be67917422199101bb8393242ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a564fe8874e464f969640e494167d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1aa475d1c6ff44ad9229c4ab9de53dbc",
              "IPY_MODEL_e122b4f8acb2479588710756dfc9e8ee",
              "IPY_MODEL_366e27c898464d1583aba9bd814ca09b"
            ],
            "layout": "IPY_MODEL_13eae79cb1c8457f802311aa59f1bec3"
          }
        },
        "1aa475d1c6ff44ad9229c4ab9de53dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_259da70bd9c140cea156369e55e24aa5",
            "placeholder": "​",
            "style": "IPY_MODEL_3c4452fb664a446aa33bb6b18a474349",
            "value": "100%"
          }
        },
        "e122b4f8acb2479588710756dfc9e8ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3e1f0b89cb5438eba7e6a578d8cb37f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe8ab94e958442fc90a15f9f8b50879e",
            "value": 1
          }
        },
        "366e27c898464d1583aba9bd814ca09b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ce5caf4764b47f5ba01f554768916cc",
            "placeholder": "​",
            "style": "IPY_MODEL_fcc1a6e437d94e7dafbadc449d5026ce",
            "value": " 1/1 [00:03&lt;00:00,  3.65s/ba]"
          }
        },
        "13eae79cb1c8457f802311aa59f1bec3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "259da70bd9c140cea156369e55e24aa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c4452fb664a446aa33bb6b18a474349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3e1f0b89cb5438eba7e6a578d8cb37f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe8ab94e958442fc90a15f9f8b50879e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ce5caf4764b47f5ba01f554768916cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcc1a6e437d94e7dafbadc449d5026ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mthsansu/MLNLP/blob/main/Code/Baseline_using_paTable.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install datasets"
      ],
      "metadata": {
        "id": "4Cbu4nNzJ1Ru"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Kx5qouClJu-Z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "from nltk.tokenize import TreebankWordTokenizer, TweetTokenizer\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import torchtext\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from termcolor import colored\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data\n",
        "git_url = \"https://raw.githubusercontent.com/mthsansu/MLNLP/main/Data/\"\n",
        "df = pd.read_csv(git_url + 'df_baseline.csv')"
      ],
      "metadata": {
        "id": "CORVZbYGJvuf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = df.drop(columns=['Unnamed: 0'])\n",
        "df = df.rename(columns={'Label': 'label'})"
      ],
      "metadata": {
        "id": "GAJRPLGkKk1I"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RbsaH_GcKnnn",
        "outputId": "39ff9347-c104-4f87-dcdd-81216d62907c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  Article de Var Matin, ce jour, sur la proposit...      0\n",
              "1  Je me réjouis de l’annonce du @gouvernementFR ...      1\n",
              "2  Une fois guéris, les enfants hospitalisés au @...      1\n",
              "3  « Progressivement nous devons avoir une foncti...      0\n",
              "4  Réaction commune, avec ma collègue députée Sab...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c5f196ba-774b-473a-a4d4-02a929f6347e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Article de Var Matin, ce jour, sur la proposit...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Je me réjouis de l’annonce du @gouvernementFR ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Une fois guéris, les enfants hospitalisés au @...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>« Progressivement nous devons avoir une foncti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Réaction commune, avec ma collègue députée Sab...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5f196ba-774b-473a-a4d4-02a929f6347e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c5f196ba-774b-473a-a4d4-02a929f6347e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c5f196ba-774b-473a-a4d4-02a929f6347e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df, test_size=0.2)"
      ],
      "metadata": {
        "id": "lzJ0YxdrKCsN"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, validate, test = \\\n",
        "              np.split(df.sample(frac=1, random_state=42), \n",
        "                       [int(.6*len(df)), int(.8*len(df))])"
      ],
      "metadata": {
        "id": "YVCh_-SlhaCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "tok = TweetTokenizer()\n",
        "tok.tokenize(\"I have a new GPU!\".lower())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4R4UVndoNjj4",
        "outputId": "9194f8ad-f04b-4c3c-b147-d237b2c7a922"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'have', 'a', 'new', 'gpu', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyarrow as pa\n",
        "import pyarrow.dataset as ds\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "# dataset = ds.dataset(pa.Table.from_pandas(df).to_batches())\n",
        "dataset = ds.dataset(pa.Table.from_pandas(train).to_batches())\n",
        "\n",
        "### convert to Huggingface dataset\n",
        "train_dataset = Dataset(pa.Table.from_pandas(train))"
      ],
      "metadata": {
        "id": "KwKatHK-KQeK"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Run only once: 8 min long\n",
        "# # fasttext vectors can be imported through torch text (it will download it only once)\n",
        "# from torchtext.vocab import GloVe, vocab, FastText\n",
        "\n",
        "# # pretrained_vectors = GloVe(name=\"6B\", dim='50')\n",
        "# pretrained_vectors = FastText(language='en')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g1ZMtPULNhI",
        "outputId": "80b6dbdc-bd26-43a9-b040-bbc7ab1bb173"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/wiki.en.vec: 6.60GB [02:30, 43.8MB/s]                            \n",
            "  0%|          | 0/2519370 [00:00<?, ?it/s]Skipping token b'2519370' with 1-dimensional vector [b'300']; likely a header\n",
            "100%|██████████| 2519370/2519370 [05:54<00:00, 7100.93it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import GloVe, FastText, vocab\n",
        "\n",
        "pretrained_vocab = vocab(pretrained_vectors.stoi)\n",
        "unk_token = \"<unk>\"\n",
        "unk_index = 0\n",
        "pad_token = '<pad>'\n",
        "pad_index = 1\n",
        "pretrained_vocab.insert_token(\"<unk>\",unk_index)\n",
        "pretrained_vocab.insert_token(\"<pad>\", pad_index)\n",
        "#this is necessary otherwise it will throw runtime error if OOV token is queried \n",
        "pretrained_vocab.set_default_index(unk_index)\n",
        "pretrained_embeddings = pretrained_vectors.vectors\n",
        "pretrained_embeddings = torch.cat((torch.zeros(1,pretrained_embeddings.shape[1]),pretrained_embeddings))\n",
        "pretrained_embeddings.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3ZFKJIQKbLT",
        "outputId": "f8739dc0-c6c2-49b0-946f-5501e88b432d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2519371, 300])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_pad_numericalize(entry, vocab_stoi, max_length=20):\n",
        "  text = [ vocab_stoi[token] if token in vocab_stoi else vocab_stoi['<unk>'] for token in tok.tokenize(entry.lower())]\n",
        "  padded_text = None\n",
        "  if len(text) < max_length:   padded_text = text + [ vocab_stoi['<pad>'] for i in range(len(text), max_length) ] \n",
        "  elif len(text) > max_length: padded_text = text[:max_length]\n",
        "  else:                        padded_text = text\n",
        "  return padded_text\n",
        "\n",
        "def tokenize_all(entries, vocab_stoi):\n",
        "  res = {}\n",
        "  res['text'] = [tokenize_pad_numericalize(entry, vocab_stoi, max_length=200) for entry in entries['text']]\n",
        "  res['label'] = entries['label']\n",
        "  return res\n",
        "\n",
        "train_dataset = train_dataset.map(lambda e: tokenize_all(e, pretrained_vocab.get_stoi()), batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "824404c329a24440aef6207074197f2b",
            "887a138e59d04e3c9674dde064ac6278",
            "5c7d3228a72a4209a355cae288b844ce",
            "696a603a2eb442f895ec6a23ef921be3",
            "589d834e1d744425b97c1355485425a5",
            "aa1b12be5a654cad93a1e3acdb0cc381",
            "0498f04b3d5b41a6ad2b453b5fe9ead5",
            "21054baf6e9149bfb9858b70b8407320",
            "1906924a76a349aeba20575bf98fc6eb",
            "3a138bbee84f43d099c179464dc528b2",
            "a1046be67917422199101bb8393242ba"
          ]
        },
        "id": "XHkXeFxGKsCV",
        "outputId": "d1e0dc32-a4f5-404d-fe17-6f5482091ca9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "824404c329a24440aef6207074197f2b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset['text'][:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ulfav-A1NYyu",
        "outputId": "9b8b4a9d-75fa-4ca9-c4cb-834a9ccba7cc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 0, 4993, 16000, 1203, 58532, 20265, 28744, 1056632, 0, 0, 0, 2, 0, 0, 0, 1263972, 11133, 71285, 119, 1184191, 119, 369, 0, 40894, 119, 331, 261, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [214, 109513, 655467, 5062, 2194, 1265132, 0, 214, 0, 175099, 119, 0, 4993, 11133, 401314, 0, 92286, 0, 1333, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset = ds.dataset(pa.Table.from_pandas(test).to_batches())\n",
        "\n",
        "### convert to Huggingface dataset\n",
        "test_dataset = Dataset(pa.Table.from_pandas(test))\n",
        "\n",
        "# tokenize\n",
        "test_dataset = test_dataset.map(lambda e: tokenize_all(e, pretrained_vocab.get_stoi()), batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "7a564fe8874e464f969640e494167d75",
            "1aa475d1c6ff44ad9229c4ab9de53dbc",
            "e122b4f8acb2479588710756dfc9e8ee",
            "366e27c898464d1583aba9bd814ca09b",
            "13eae79cb1c8457f802311aa59f1bec3",
            "259da70bd9c140cea156369e55e24aa5",
            "3c4452fb664a446aa33bb6b18a474349",
            "b3e1f0b89cb5438eba7e6a578d8cb37f",
            "fe8ab94e958442fc90a15f9f8b50879e",
            "2ce5caf4764b47f5ba01f554768916cc",
            "fcc1a6e437d94e7dafbadc449d5026ce"
          ]
        },
        "id": "GX9Znj6obvff",
        "outputId": "341ef694-3d39-4eae-a37f-2c1c05e59278"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a564fe8874e464f969640e494167d75"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_dataset['text'][:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZCiEaPLcY9c",
        "outputId": "6a831d9e-ed6f-411d-d712-0ecee0c38285"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3291, 958, 0, 13, 2194, 149238, 112, 0, 281746, 129945, 1203, 156401, 119, 2493450, 119, 12200, 1368069, 14600, 2456493, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 477635, 1230, 138476, 4032, 413, 0, 1203, 342910, 93083, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Dataset class\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "class TweetDataset(Dataset):\n",
        "    def __init__(self, data, args):\n",
        "      # args is a dict, a nice way to share the global arguments (even accross multiple files)\n",
        "      self.args = args\n",
        "      self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "      item = {\n",
        "          \"text\": np.array(self.data[idx]['text']),\n",
        "          \"label\": np.array(self.data[idx]['label'])\n",
        "      }\n",
        "      # warning: if you put   self.data['text'][idx]    it will take A LOT of time...\n",
        "      ## The following code would take forever just to print next(iter(train_loader))['text'].shape\n",
        "      # item = {\n",
        "      #     \"text\": np.array(self.data['text'][idx]),\n",
        "      #     \"label\": np.array(self.data['label'][idx])\n",
        "      # }\n",
        "      return item"
      ],
      "metadata": {
        "id": "SXji2tSecdfn"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the data loader\n",
        "\n",
        "# Create DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "args = {'bsize': 64}\n",
        "train_loader = DataLoader(TweetDataset(train_dataset, args), batch_size=args['bsize'], num_workers=2, shuffle=True, drop_last=True)\n",
        "test_loader  = DataLoader(TweetDataset(test_dataset, args), batch_size=args['bsize'], num_workers=2, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "id": "zuC4MgHbed9t"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model to classify tweets\n",
        "\n",
        "class TweetModel(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, pretrained_vectors=None):\n",
        "        \"\"\"\n",
        "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
        "        member variables.\n",
        "        \"\"\"\n",
        "        super(TweetModel, self).__init__()\n",
        "        # apply the pretrained embeddings to transform our token indices, into vectors\n",
        "        self.ebd = torch.nn.Embedding.from_pretrained(pretrained_vectors, freeze=True)\n",
        "        self.hidden_linear_layer = torch.nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
        "        self.classification_layer = torch.nn.Linear(hidden_dim, output_dim, bias=True)\n",
        "        # softmax layer to compute class probabilities\n",
        "        # https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html?highlight=softmax#torch.nn.Softmax\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "        # define the dropout strategy (here, 20% (0.2) of the vector is ignored to prevent overfitting)\n",
        "        # we don't use it here but it's a good thing to keep in mind\n",
        "        # self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        In the forward function we accept a Tensor of input data and we must return\n",
        "        a Tensor of output data. We can use Modules defined in the constructor as\n",
        "        well as arbitrary operators on Tensors.\n",
        "        \"\"\"\n",
        "        # apply the pretrained embeddings\n",
        "        x  = self.ebd(x)\n",
        "        x  = x.mean(1)\n",
        "        h  = torch.relu(self.hidden_linear_layer( x ))\n",
        "        # h  = self.dropout(h)\n",
        "        h  = self.classification_layer(h)\n",
        "        logits = self.softmax(h)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "CP8tPGD4fzkV"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sizes = next(iter(train_loader))['text'].size()\n",
        "batchsize = sizes[0]\n",
        "inputdim  = sizes[1]\n",
        "print(batchsize, inputdim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdtfJXhygGUA",
        "outputId": "c9390816-e544-4445-b46e-4fd0baf6da5f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hiddendim = 300 # dimension of the pretrained vector\n",
        "outputdim = 3 # because there is 3 classes, i.e. 3 emojis\n",
        "# we instanciate the model\n",
        "tweet_model = TweetModel(inputdim, hiddendim, outputdim, pretrained_vectors=pretrained_vectors.vectors)"
      ],
      "metadata": {
        "id": "5_QeXR2ZgNfj"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can look at the model \n",
        "tweet_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mugy8DXgSM7",
        "outputId": "4354ac11-0228-46f4-9878-0ca7d5abe16f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TweetModel(\n",
              "  (ebd): Embedding(2519370, 300)\n",
              "  (hidden_linear_layer): Linear(in_features=300, out_features=300, bias=True)\n",
              "  (classification_layer): Linear(in_features=300, out_features=3, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "  print('DEVICE = ', colored(torch.cuda.get_device_name(0), \"green\" ) )\n",
        "else:\n",
        "  device = 'cpu'\n",
        "  print('DEVICE = ', colored('CPU', \"blue\"))\n",
        "tweet_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZNH_PodgfAk",
        "outputId": "cd5e7009-7854-43d5-ee74-f5eca2af6971"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE =  \u001b[34mCPU\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TweetModel(\n",
              "  (ebd): Embedding(2519370, 300)\n",
              "  (hidden_linear_layer): Linear(in_features=300, out_features=300, bias=True)\n",
              "  (classification_layer): Linear(in_features=300, out_features=3, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "\n",
        "def train(model, optimizer, ep, args):\n",
        "  # set the model into a training mode : the model's weights and parameters WILL BE updated!\n",
        "  model.train()\n",
        "  # initialize empty lists for losses and accuracies\n",
        "  loss_it, acc_it = list(), list()\n",
        "\n",
        "  # start the loop over all the training batches. This means one full epoch.\n",
        "  for it, batch in tqdm(enumerate(train_loader), desc=\"Epoch %s:\" % (ep), total=train_loader.__len__()):\n",
        "    \n",
        "    batch = {'text': batch['text'].to(device), 'label': batch['label'].to(device)}\n",
        "\n",
        "    # put parameters of the model and the optimizer to zero before doing another iteration. this prevents the gradient accumulation through batches\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # apply the model on the batch\n",
        "    logits = model(batch['text'])\n",
        "\n",
        "    # # # to deal with unbalanced data in the batch, we calculate the weights according to their inverse frequency\n",
        "    b_counter = Counter(batch['label'].detach().cpu().tolist())\n",
        "    b_weights = torch.tensor( [ sum(batch['label'].detach().cpu().tolist()) / b_counter[label] if b_counter[label] > 0 else 0 for label in list(range(args['num_class'])) ] )\n",
        "    b_weights = b_weights.to(device)\n",
        "\n",
        "    # we choose the CrossEntropyLoss, suitable for multiclass classification\n",
        "    # https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss\n",
        "    loss_function = nn.CrossEntropyLoss(weight=b_weights)\n",
        "    # loss_function = nn.CrossEntropyLoss()\n",
        "    loss = loss_function(logits, batch['label'])\n",
        "\n",
        "    # compute backpropagation\n",
        "    loss.backward()\n",
        "\n",
        "    # indicate to the optimizer we've done a step\n",
        "    optimizer.step()\n",
        "\n",
        "    # append the value of the loss for the current iteration (it). .item() retrieve the nuclear value as a int/long\n",
        "    loss_it.append(loss.item())\n",
        "\n",
        "    # get the predicted tags using the maximum probability from the softmax\n",
        "    _, tag_seq  = torch.max(logits, 1)\n",
        "    \n",
        "    # Those 3 lines compute the accuracy and then append it the same way as the loss above\n",
        "    correct = (tag_seq.flatten() == batch['label'].flatten()).float().sum()\n",
        "    acc = correct / batch['label'].flatten().size(0)\n",
        "    acc_it.append(acc.item())\n",
        "\n",
        "  # simple averages of losses and accuracies for this epoch\n",
        "  loss_it_avg = sum(loss_it)/len(loss_it)\n",
        "  acc_it_avg = sum(acc_it)/len(acc_it)\n",
        "  \n",
        "  # print useful information about the training progress and scores on this training set's full pass (i.e. 1 epoch)\n",
        "  print(\"Epoch %s/%s : %s : (%s %s) (%s %s)\" % (colored(str(ep), 'blue'),args['max_eps'] , colored('Training', 'blue'), colored('loss', 'cyan'), sum(loss_it)/len(loss_it), colored('acc', 'cyan'), sum(acc_it) / len(acc_it)))\n"
      ],
      "metadata": {
        "id": "_hXhNntzgxVa"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(target, loader, model):\n",
        "  \"\"\"\n",
        "    Args:\n",
        "      target (str): modify the display, usually either 'validation' or 'test'\n",
        "  \"\"\"\n",
        "\n",
        "  # set the model into a evaluation mode : the model's weights and parameters will NOT be updated!\n",
        "  model.eval()\n",
        "\n",
        "  # intialize empty list to populate later on\n",
        "  loss_it, acc_it, f1_it = list(), list(), list()\n",
        "  # preds = predicted values ; trues = true values .... obviously~\n",
        "  preds, trues = list(), list()\n",
        "\n",
        "  # loop over the loader batches\n",
        "  for it, batch in tqdm(enumerate(loader), desc=\"%s:\" % (target), total=loader.__len__()):\n",
        "    # set an environnement without any gradient. So the tensor gradients are not considered \n",
        "    # (saves a lot of computation and memory, this is one of the many things that makes predicting far less costly than training)\n",
        "    with torch.no_grad():\n",
        "\n",
        "      # put the batch to the correct device\n",
        "      batch = {'text': batch['text'].to(device), 'label': batch['label'].to(device)}\n",
        "\n",
        "      # apply the model\n",
        "      logits = model(batch['text'])\n",
        "\n",
        "      # # to deal with unbalanced data in the batch, we calculate the weights according to their inverse frequency\n",
        "      # b_counter = Counter(batch['label'].detach().cpu().tolist())\n",
        "      # b_weights = torch.tensor( [ sum(batch['label'].detach().cpu().tolist()) / b_counter[label] if b_counter[label] > 0 else 0 for label in list(range(20)) ] )\n",
        "      # b_weights = b_weights.to(device)\n",
        "\n",
        "      # loss_function = nn.CrossEntropyLoss(weight=b_weights)\n",
        "      loss_function = nn.CrossEntropyLoss()\n",
        "      loss = loss_function(logits, batch['label'])\n",
        "\n",
        "      # no need to backward() and other training stuff. Directly store the loss in the list\n",
        "      loss_it.append(loss.item())\n",
        "\n",
        "      # get the predicted tags using the maximum probability from the softmax\n",
        "      _, tag_seq  = torch.max(logits, 1)\n",
        "      \n",
        "      # compute the accuracy and store it\n",
        "      correct = (tag_seq.flatten() == batch['label'].flatten()).float().sum()\n",
        "      acc = correct / batch['label'].flatten().size(0)\n",
        "      acc_it.append(acc.item())\n",
        "      \n",
        "      # extend the predictions and true labels lists so we can compare them later on\n",
        "      # note how we first ensure the tensor are on cpu (.cpu()), then we detach() the gradient from the tensor, before transforming it to a simple python list (.tolist())\n",
        "      preds.extend(tag_seq.cpu().detach().tolist())\n",
        "      trues.extend(batch['label'].cpu().detach().tolist())\n",
        "\n",
        "  # compute the average loss and accuracy accross the iterations (batches)\n",
        "  loss_it_avg = sum(loss_it)/len(loss_it)\n",
        "  acc_it_avg = sum(acc_it)/len(acc_it)\n",
        "  \n",
        "  # print useful information. Important during training as we want to know the performance over the validation set after each epoch\n",
        "  print(\"%s : (%s %s) (%s %s)\" % ( colored(target, 'blue'), colored('loss', 'cyan'), sum(loss_it)/len(loss_it), colored('acc', 'cyan'), sum(acc_it) / len(acc_it)))\n",
        "\n",
        "  # return the true and predicted values with the losses and accuracies\n",
        "  return trues, preds, loss_it_avg, acc_it_avg, loss_it, acc_it"
      ],
      "metadata": {
        "id": "mBf4ICGbg29I"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "def run_epochs(model, args):\n",
        "\n",
        "  args['device'] =device\n",
        "  # if args['cuda'] != -1:\n",
        "  #     model.cuda(args['cuda'])\n",
        "  #     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  #     args['device'] = device\n",
        "  #     print(\"device set to %s\" % (device) )\n",
        "\n",
        "  # we set the optimizer as Adam with the learning rate (lr) set in the arguments\n",
        "  # you can look at the different optimizer available here: https://pytorch.org/docs/stable/optim.html\n",
        "  optimizer = optim.Adam(model.parameters(), lr = args['lr'])\n",
        "\n",
        "  # define an empty list to store validation losses for each epoch\n",
        "  val_ep_losses = list()\n",
        "  # iterate over the number of max epochs set in the arguments\n",
        "  for ep in range(args['max_eps']):\n",
        "    # train the model using our defined function\n",
        "    train(model, optimizer, ep, args)\n",
        "    # apply the model for inference using our defined function\n",
        "    trues, preds, val_loss_it_avg, val_acc_it_avg, val_loss_it, val_acc_it = inference(\"validation\", val_loader, model)\n",
        "    # append the validation losses (good losses should normally go down)\n",
        "    val_ep_losses.append(val_loss_it_avg)\n",
        "\n",
        "  # return the list of epoch validation losses in order to use it later to create a plot\n",
        "  return val_ep_losses\n",
        "    "
      ],
      "metadata": {
        "id": "y6_AqJD8g5Fh"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here you can specify if you want a GPU or a CPU by setting the cuda argument as -1 for CPU and another index for GPU. If you only have one GPU, put 0.\n",
        "args.update({'max_eps': 10, 'lr': 0.001, 'device': 'cpu', 'cuda': 0, 'num_class': 3})\n",
        "# 1e-05\n",
        "print('device', device)\n",
        "# Instantiate model with pre-trained glove vectors\n",
        "# model = TweetModel(pretrained_embeddings, args['num_class'], args, dimension=50, freeze_embeddings = True )\n",
        "tweet_model = TweetModel(inputdim, hiddendim, outputdim, pretrained_vectors=pretrained_vectors.vectors)\n",
        "loss_list_val = run_epochs(tweet_model, args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "q6GhkWbTg_YT",
        "outputId": "20e4ea36-f49b-4920-efe4-dcd28586337f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:: 100%|██████████| 12/12 [00:00<00:00, 19.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch \u001b[34m0\u001b[0m/10 : \u001b[34mTraining\u001b[0m : (\u001b[36mloss\u001b[0m 1.0972521901130676) (\u001b[36macc\u001b[0m 0.4049479166666667)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-b68ad6400231>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# model = TweetModel(pretrained_embeddings, args['num_class'], args, dimension=50, freeze_embeddings = True )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtweet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTweetModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddendim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_vectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mloss_list_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-70-48291f0ac95a>\u001b[0m in \u001b[0;36mrun_epochs\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# apply the model for inference using our defined function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mtrues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_it_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_it_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_it\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;31m# append the validation losses (good losses should normally go down)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mval_ep_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss_it_avg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'val_loader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dGYEF5tyhFuR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}